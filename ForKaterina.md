The current state of our AI tutor's ("PyTutor") development can be split into two parts: the student-facing application, and the AI tutor backend. 

- **_Student-facing application_:** this fall we will offer students in intro to programming courses (at MIT, GSU, and QCC) a platform for creating “workspaces” tied to their different course-events (e.g. Lecture 1, Assignment 2, etc.). 
    - Each workspace offers a fully featured code editor (pre-configured for python), in-browser code execution, a whiteboarding tool, and our AI tutor (currently accessible via a chat window and described more below). 
        - By having different editors integrated directly into our platform, we can support seamless AI-assisted interactions. For example, if a student executes code that results in an error, they can easily attach both the code and error to their message to the AI tutor, making for a frictionless experience. 
    - Workspaces can be made “collaborative” and shared with others, allowing for students and human tutors to code, diagram, chat (over voice call), and work together. 
        - This will enable us to collect rich peer-to-peer and human-to-peer interaction data (this fall in our MIT course) which will be used to both evaluate and fine-tune our AI tutor. 
    - Overall, the workspace functionality (like in-browser code execution and the ability to collaborate) aims to be useful to students even outside of the AI-powered features, so that we can encourage them to use the platform as much as possible. This supports both our data-collection needs, as well as creating the most effective AI-powered interactions, as the more context we can have about the student, the more personalized the AI assistance can be.
- **_AI backend_:** our AI functionality currently leverages paid LLM services accessed through APIs (predominantly GPT4o from OpenAI), combined with our prompting framework that aims to steer the LLM to respond to student queries in both a personalized and pedegogically-sound manner.
    - **_Prompting framework:_** The goal of our prompting framework is to both (1) give the LLM context about the course and student so it can generate responses tailored to their current learning needs, and (2) influence the LLMs generation to invoke the instruction style of an effective tutor (e.g. using the socratic method, making the material personnaly meaningful to the student, etc.). Below are some of our current strategies, but **this will be a key area of research this fall and in the upcoming year.** 
        - **_Course Event Descriptions:_** As a preprocessing step, we ingest all of the content of the course (e.g. syllabus, letcure slides, lecture transcripts, problem sets) and use LLMs to generate summaries / descriptions of each course event. We do this recursively, so that when generating the description of a course event that builds on another (for example, a quiz across the previous two lectures), the LLM is able to 'see' both the raw course material related to the specific event as well as the generated descriptions of it's 'ancestor' course events.
        - **_Course Event Specific Instructions:_** Because we steer students to operate in workspaces tied to a specific course event, we can provide the LLM with explicit instructions based on the type of the event the student is working on. This is both to encourage good tutoring behavior by the LLM, as well as try to prevent the tutor from being abused and/or doing too much for the student. For example, if the student is in a workspace tied to a lecture, we can assume they are trying to clarify their understanding of the material, and are more willing to generate code samples. While if the student is working on a problem set, we want the tutor not to generate code and instead guide the student to their own solutions. 
            - It's important to note that these instructions behave merely as suggestions to LLMs and **creating a more full-proof system (that doesn't sacrifice the open-ended nature of LLMs) is an active area of research.**
        - **_Student progress assessment_** _(course event)_: As the student works with the platform, we will periodically feed their chat history and workspace artifacts (e.g. their code + execution results) into a seperate LLM call to generate a summary of the student's progress through the learning objectives of the course event (outlined in the Course Event Description from above). This description is then sent off with student queries to hopefully influence the LLM to cater it's responses to the learning state of the student. **The generation, representation, and usage of the student progress assessment will be an active area of research this fall.**
        - **_Student progress assessment_** _(course-wide)_: We plan to apply a similar strategy to the above, but across the entire course, feeding the generated student progress assessments for course events into an LLM and generating a progress assessment across the global learning objectives of the course. Determing if this is accurate and effective is still an open question.
        - **_Relevant course snippets_:** we use the industry-standard technique of Retrieval Augmented Generation (RAG) to identify snippets from course documents that are most relevant to the student's current query. These snippets are then given to the LLM to hopefully limit hallucinations and ground the generation in the material that the student is familiar with. We also surface these snippets back to the user so they can get a sense of what the LLM's response is based on. 
    - Usage: Currently the AI tutor is only reactive to student queries, meaning the tutor only acts when the student prompts it to. **Exploring a 'proactive' tutor will be something we research this fall, and we will likely conduct an explicit experiment at GSU to determine the efficacy of a proactive vs reactive AI-powered tutor.**

Some of our research focuses are outlined above, but I'll call out the following projects that are likely to kick off this semester led by student researchers (and will continue for at least the year):
- **_Improved student learning representation:_** I outlined above our rudimentary strategy for using LLMs to summarize student progress, which we will work to improve this year, both by refining how we prompt the AI (perhaps using more structured approaches like knowledge graphs) as well as explicitly modeling student learning (like with POMDPs). The goal of both approaches would be to reliably identify where the student is at in their learning journey and then determine the best action to transition them to next learning state. 
- **_Tutor Persona:_** Given that some of our team is from the Personal Robots Group, it is of course a priority to make sure our AI Tutor is personable in addition to being effective. We also recognize that different students will prefer and respond best to different conversation styles, so we must explore the controls we should offer for users to control their tutor's persona, as well as systems to identify the persona that best serves the student.
- **_Group interactions with an AI Tutor:_** like many other systems, our AI tutor currently functions as a 1-on-1 chat bot, but the collaborative nature of our platform allows us to explore what AI tutor interactions should be like when working with a group of students. We will explore how best to tackle personalization when a tutor is interacting with multiple users (who can have different preferences and be at different stages of learning). Additionally, it's possible that this group-oriented tutor could be made more effective by encouraging peer-to-peer learning.
- **_Test Case Runner UI:_** We plan to implement a test case runner into PyTutor’s UI to allow students to write and execute test cases on their programs. Additionally, we hope to explore through focus groups how the inclusion of the test case runner augments student learning, as test cases allow the students to effectively describe the expected behavior of the program.
- **_AI Tutor interactions with instructor:_** this will be a larger focus for the spring, but we are also considering how the AI tutor should interact with instructors, both sharing insights the AI tutor gathers about students, as well as enabling the instructor to guide and influence the behavior of the tutor. 

All of the above research projects will be underpinned by work to expand our evaluation framework to help us understand how our prompting strategies (and perhaps usage of different models) is actually affecting the efficacy of our tutoring agent. This work is difficult given the fuzzy and (typically) unstructured nature of LLM interactions, but essential in learning how to get the most out of LLMs for tutoring usecases. 

Looking ahead to the future / next few years, I think there are two large areas for potential research:
- **_Tighter integration with course management systems:_** currently our platform is not integrated with actual course websites (primarily for IRB & ethical reasons). This means our tutor is not aware of how a student actually performs on course assignments & assessments, and their progress is only visible to us in terms of how they use our platform (which is not required) -- this is partly why we are fixated on making our platform useful to students, so that they will hopefully use it more and thus we can learn more about them and their progress. It is interesting to consider how our system could be improved if we could have as much context about the student as, say, the instructor does. This of course presents privacy & accountability concerns, which should also be explored as part of this research.  
- **_Novel interactions given AI-assistance:_** currently, our tutor aims to complement the courses as they exist today (e.g. clarifying lecture material, offering homework help on existing problem sets, etc.), but it's interesting to consider if and how courses could be restructured given the presence of an AI Tutor. For example, I think it could be possible that courses emphasize testing and evaluating code earlier, as there might be an assumption students will be interacting significantly with AI generated code. 
